{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download weights from drive before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T13:50:15.856738400Z",
     "start_time": "2023-09-28T13:50:08.621051800Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from STYLEGAN2.utils.utils_stylegan2 import convert_images_to_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T13:50:15.872131500Z",
     "start_time": "2023-09-28T13:50:15.856738400Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_and_plot_images(gen, seed, w_avg, truncation_psi=1):\n",
    "    \"\"\" plot images from generator output \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3,figsize=(15,15))\n",
    "    for i in range(3):\n",
    "    \n",
    "        # creating random latent vector\n",
    "        rnd = np.random.RandomState(seed)\n",
    "        z = rnd.randn(1, 512).astype('float32')\n",
    "\n",
    "        # running mapping network\n",
    "        dlatents = gen.mapping_network(z)\n",
    "        # adjusting dlatents depending on truncation psi, if truncatio_psi = 1, no adjust\n",
    "        dlatents = w_avg + (dlatents - w_avg) * truncation_psi \n",
    "        # running synthesis network\n",
    "        out = gen.synthesis_network(dlatents)\n",
    "\n",
    "        #converting image/s to uint8\n",
    "        img = convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n",
    "\n",
    "        #plotting images\n",
    "        ax[i].axis('off')\n",
    "        img_plot = ax[i].imshow(img.numpy()[0])\n",
    "        \n",
    "        seed += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T13:50:15.890282300Z",
     "start_time": "2023-09-28T13:50:15.872131500Z"
    }
   },
   "outputs": [],
   "source": [
    "impl = 'cuda' # 'ref' if cuda is not available in your machine\n",
    "gpu = True # False if tensorflow cpu is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load stylegan2 generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T13:50:15.919471700Z",
     "start_time": "2023-09-28T13:50:15.890282300Z"
    }
   },
   "outputs": [],
   "source": [
    "from STYLEGAN2.stylegan2_generator import StyleGan2Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading ffhq stylegan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T13:50:30.866062400Z",
     "start_time": "2023-09-28T13:50:18.181584600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Failed!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception encountered when calling layer \"Conv0_up\" \"                 f\"(type ModulatedConv2DLayer).\n\nNVCC returned an error. See below for full command line and output log:\n\nnvcc --std=c++11 -DNDEBUG \"C:\\Users\\kiril\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\dnnlib\\ops\\upfirdn_2d.cu\" --preprocess -o \"C:\\Users\\kiril\\AppData\\Local\\Temp\\tmptk2vbkaj\\upfirdn_2d_tmp.cu\" --keep --keep-dir \"C:\\Users\\kiril\\AppData\\Local\\Temp\\tmptk2vbkaj\" --disable-warnings --include-path \"C:\\Users\\kiril\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\include\" --include-path \"C:\\Users\\kiril\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\include\\external\\protobuf_archive\\src\" --include-path \"C:\\Users\\kiril\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\include\\external\\com_google_absl\" --include-path \"C:\\Users\\kiril\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\include\\external\\eigen_archive\" --compiler-bindir \"C:/Program Files (x86)/Microsoft Visual Studio/2022/BuildTools/VC/Tools/MSVC/14.37.32822/bin/Hostx64/x64\" 2>&1\n\nupfirdn_2d.cu\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\include\\crt/host_config.h(160): fatal error C1189: #error:  -- unsupported Microsoft Visual Studio version! Only the versions between 2017 and 2019 (inclusive) are supported! The nvcc flag '-allow-unsupported-compiler' can be used to override this version check; however, using an unsupported host compiler may cause compilation failure or incorrect run time execution. Use at your own risk.\nnvcc warning : The -std=c++11 flag is not supported with the configured host compiler. Flag will be ignored.\n\n\nCall arguments received by layer \"Conv0_up\" \"                 f\"(type ModulatedConv2DLayer):\n  • x=tf.Tensor(shape=(1, 512, 4, 4), dtype=float32)\n  • dlatent_vect=tf.Tensor(shape=(1, 512), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m weights_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mffhq\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;66;03m# face model trained by Nvidia\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# instantiating generator network\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m generator \u001B[38;5;241m=\u001B[39m \u001B[43mStyleGan2Generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimpl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimpl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgpu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgpu\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# loading w average\u001B[39;00m\n\u001B[0;32m      7\u001B[0m w_average \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweights/\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_dlatent_avg.npy\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(weights_name))\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\stylegan2_generator.py:150\u001B[0m, in \u001B[0;36mStyleGan2Generator.__init__\u001B[1;34m(self, resolution, weights, impl, gpu, **kwargs)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;66;03m# load weights\u001B[39;00m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    149\u001B[0m     \u001B[38;5;66;03m#we run the network to define it, not the most efficient thing to do...\u001B[39;00m\n\u001B[1;32m--> 150\u001B[0m     _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__load_weights(weights)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\stylegan2_generator.py:166\u001B[0m, in \u001B[0;36mStyleGan2Generator.call\u001B[1;34m(self, z)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    155\u001B[0m \n\u001B[0;32m    156\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    163\u001B[0m \n\u001B[0;32m    164\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    165\u001B[0m dlatents \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmapping_network(z)\n\u001B[1;32m--> 166\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msynthesis_network\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdlatents\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\stylegan2_generator.py:108\u001B[0m, in \u001B[0;36mSynthesisNetwork.call\u001B[1;34m(self, dlatents_in)\u001B[0m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;66;03m# Main layers\u001B[39;00m\n\u001B[0;32m    107\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresolution_log2 \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m--> 108\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlayer_\u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;124;43m_\u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;124;43m_up\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mres\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mres\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdlatents_in\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mres\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    109\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlayer_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mres, \u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mres))(x, dlatents_in[:, res\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m4\u001B[39m])\n\u001B[0;32m    110\u001B[0m     y \u001B[38;5;241m=\u001B[39m upsample_2d(y, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresample_kernel, impl\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimpl, gpu\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgpu)\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\layers\\synthesis_main_layer.py:37\u001B[0m, in \u001B[0;36mSynthesisMainLayer.call\u001B[1;34m(self, x, dlatent_vect)\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, dlatent_vect):\n\u001B[1;32m---> 37\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmod_conv2d_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdlatent_vect\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;66;03m#randomize noise\u001B[39;00m\n\u001B[0;32m     40\u001B[0m     noise \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mnormal([tf\u001B[38;5;241m.\u001B[39mshape(x)[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m, x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m], x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m3\u001B[39m]], dtype\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdtype)\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\layers\\modulated_conv_2d_layer.py:82\u001B[0m, in \u001B[0;36mModulatedConv2DLayer.call\u001B[1;34m(self, x, dlatent_vect)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mup:\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgpu:\n\u001B[1;32m---> 82\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mupsample_conv_2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mNCHW\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresample_kernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimpl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimpl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     84\u001B[0m         x \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mtranspose(x, [\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m])\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\dnnlib\\ops\\upfirdn_2d.py:297\u001B[0m, in \u001B[0;36mupsample_conv_2d\u001B[1;34m(x, w, k, factor, gain, data_format, impl, gpu)\u001B[0m\n\u001B[0;32m    295\u001B[0m \u001B[38;5;66;03m# Execute.\u001B[39;00m\n\u001B[0;32m    296\u001B[0m x \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mconv2d_transpose(x, w, output_shape\u001B[38;5;241m=\u001B[39moutput_shape, strides\u001B[38;5;241m=\u001B[39mstride, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVALID\u001B[39m\u001B[38;5;124m'\u001B[39m, data_format\u001B[38;5;241m=\u001B[39mdata_format)\n\u001B[1;32m--> 297\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_simple_upfirdn_2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mfactor\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimpl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimpl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgpu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgpu\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\dnnlib\\ops\\upfirdn_2d.py:364\u001B[0m, in \u001B[0;36m_simple_upfirdn_2d\u001B[1;34m(x, k, up, down, pad0, pad1, data_format, impl, gpu)\u001B[0m\n\u001B[0;32m    362\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNCHW\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    363\u001B[0m     y \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreshape(y, [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, _shape(y, \u001B[38;5;241m2\u001B[39m), _shape(y, \u001B[38;5;241m3\u001B[39m), \u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m--> 364\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43mupfirdn_2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mup\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mup\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdown\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdowny\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdown\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadx0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadx1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpady0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpady1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimpl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimpl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgpu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgpu\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNCHW\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    366\u001B[0m     y \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreshape(y, [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, _shape(x, \u001B[38;5;241m1\u001B[39m), _shape(y, \u001B[38;5;241m1\u001B[39m), _shape(y, \u001B[38;5;241m2\u001B[39m)])\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\dnnlib\\ops\\upfirdn_2d.py:62\u001B[0m, in \u001B[0;36mupfirdn_2d\u001B[1;34m(x, k, upx, upy, downx, downy, padx0, padx1, pady0, pady1, impl, gpu)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Pad, upsample, FIR filter, and downsample a batch of 2D images.\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \n\u001B[0;32m     22\u001B[0m \u001B[38;5;124;03mAccepts a batch of 2D images of the shape `[majorDim, inH, inW, minorDim]`\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;124;03m    Tensor of the shape `[majorDim, outH, outW, minorDim]`, and same datatype as `x`.\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     58\u001B[0m impl_dict \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mref\u001B[39m\u001B[38;5;124m'\u001B[39m:  _upfirdn_2d_ref,\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m: _upfirdn_2d_cuda,\n\u001B[0;32m     61\u001B[0m }\n\u001B[1;32m---> 62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimpl_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[43mimpl\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdowny\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdowny\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadx0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadx1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpady0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpady0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpady1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpady1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgpu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgpu\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\dnnlib\\ops\\upfirdn_2d.py:145\u001B[0m, in \u001B[0;36m_upfirdn_2d_cuda\u001B[1;34m(x, k, upx, upy, downx, downy, padx0, padx1, pady0, pady1, gpu)\u001B[0m\n\u001B[0;32m    143\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m dx, func\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m y, grad\n\u001B[1;32m--> 145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\dnnlib\\ops\\upfirdn_2d.py:137\u001B[0m, in \u001B[0;36m_upfirdn_2d_cuda.<locals>.func\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;129m@tf\u001B[39m\u001B[38;5;241m.\u001B[39mcustom_gradient\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfunc\u001B[39m(x):\n\u001B[1;32m--> 137\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43m_get_plugin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mup_fir_dn2d(x\u001B[38;5;241m=\u001B[39mx, k\u001B[38;5;241m=\u001B[39mkc, upx\u001B[38;5;241m=\u001B[39mupx, upy\u001B[38;5;241m=\u001B[39mupy, downx\u001B[38;5;241m=\u001B[39mdownx, downy\u001B[38;5;241m=\u001B[39mdowny, padx0\u001B[38;5;241m=\u001B[39mpadx0, padx1\u001B[38;5;241m=\u001B[39mpadx1, pady0\u001B[38;5;241m=\u001B[39mpady0, pady1\u001B[38;5;241m=\u001B[39mpady1)\n\u001B[0;32m    138\u001B[0m     y\u001B[38;5;241m.\u001B[39mset_shape([majorDim, outH, outW, minorDim])\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;129m@tf\u001B[39m\u001B[38;5;241m.\u001B[39mcustom_gradient\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgrad\u001B[39m(dy):\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\dnnlib\\ops\\upfirdn_2d.py:15\u001B[0m, in \u001B[0;36m_get_plugin\u001B[1;34m()\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_plugin\u001B[39m():\n\u001B[1;32m---> 15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcustom_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_plugin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitext\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;18;43m__file__\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m.cu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\dnnlib\\custom_ops.py:112\u001B[0m, in \u001B[0;36mget_plugin\u001B[1;34m(cuda_file)\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tempfile\u001B[38;5;241m.\u001B[39mTemporaryDirectory() \u001B[38;5;28;01mas\u001B[39;00m tmp_dir:\n\u001B[0;32m    111\u001B[0m     tmp_file \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(tmp_dir, cuda_file_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_tmp\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m cuda_file_ext)\n\u001B[1;32m--> 112\u001B[0m     _run_cmd(_prepare_nvcc_cli(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m --preprocess -o \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m --keep --keep-dir \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (cuda_file, tmp_file, tmp_dir)))\n\u001B[0;32m    113\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(tmp_file, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m    114\u001B[0m         bad_file_str \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m cuda_file\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mencode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# __FILE__ in error check macros\u001B[39;00m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\dnnlib\\custom_ops.py:62\u001B[0m, in \u001B[0;36m_run_cmd\u001B[1;34m(cmd)\u001B[0m\n\u001B[0;32m     60\u001B[0m     status \u001B[38;5;241m=\u001B[39m pipe\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 62\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNVCC returned an error. See below for full command line and output log:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (cmd, output))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Exception encountered when calling layer \"Conv0_up\" \"                 f\"(type ModulatedConv2DLayer).\n\nNVCC returned an error. See below for full command line and output log:\n\nnvcc --std=c++11 -DNDEBUG \"C:\\Users\\kiril\\OneDrive\\Desktop\\DIPLOMA\\DIP\\STYLEGAN2\\dnnlib\\ops\\upfirdn_2d.cu\" --preprocess -o \"C:\\Users\\kiril\\AppData\\Local\\Temp\\tmptk2vbkaj\\upfirdn_2d_tmp.cu\" --keep --keep-dir \"C:\\Users\\kiril\\AppData\\Local\\Temp\\tmptk2vbkaj\" --disable-warnings --include-path \"C:\\Users\\kiril\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\include\" --include-path \"C:\\Users\\kiril\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\include\\external\\protobuf_archive\\src\" --include-path \"C:\\Users\\kiril\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\include\\external\\com_google_absl\" --include-path \"C:\\Users\\kiril\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\include\\external\\eigen_archive\" --compiler-bindir \"C:/Program Files (x86)/Microsoft Visual Studio/2022/BuildTools/VC/Tools/MSVC/14.37.32822/bin/Hostx64/x64\" 2>&1\n\nupfirdn_2d.cu\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\include\\crt/host_config.h(160): fatal error C1189: #error:  -- unsupported Microsoft Visual Studio version! Only the versions between 2017 and 2019 (inclusive) are supported! The nvcc flag '-allow-unsupported-compiler' can be used to override this version check; however, using an unsupported host compiler may cause compilation failure or incorrect run time execution. Use at your own risk.\nnvcc warning : The -std=c++11 flag is not supported with the configured host compiler. Flag will be ignored.\n\n\nCall arguments received by layer \"Conv0_up\" \"                 f\"(type ModulatedConv2DLayer):\n  • x=tf.Tensor(shape=(1, 512, 4, 4), dtype=float32)\n  • dlatent_vect=tf.Tensor(shape=(1, 512), dtype=float32)"
     ]
    }
   ],
   "source": [
    "weights_name = 'ffhq' # face model trained by Nvidia\n",
    "\n",
    "# instantiating generator network\n",
    "generator = StyleGan2Generator(weights=weights_name, impl=impl, gpu=gpu)\n",
    "\n",
    "# loading w average\n",
    "w_average = np.load('weights/{}_dlatent_avg.npy'.format(weights_name))\n",
    "\n",
    "# not using truncation\n",
    "generate_and_plot_images(generator, seed=96, w_avg=w_average)\n",
    "\n",
    "# using truncation 0.5\n",
    "generate_and_plot_images(generator, seed=96, w_avg=w_average, truncation_psi=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading car stylegan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = 'car' # church model trained by Nvidia\n",
    "\n",
    "# instantiating generator network\n",
    "generator = StyleGan2Generator(weights=weights_name, impl=impl, gpu=gpu)\n",
    "\n",
    "# loading w average\n",
    "w_average = np.load('weights/{}_dlatent_avg.npy'.format(weights_name))\n",
    "\n",
    "# not using truncation\n",
    "generate_and_plot_images(generator, seed=4, w_avg=w_average)\n",
    "\n",
    "# using truncation 0.5\n",
    "generate_and_plot_images(generator, seed=4, w_avg=w_average, truncation_psi=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading cat stylegan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = 'cat' # church model trained by Nvidia\n",
    "\n",
    "# instantiating generator network\n",
    "generator = StyleGan2Generator(weights=weights_name, impl=impl, gpu=gpu)\n",
    "\n",
    "# loading w average\n",
    "w_average = np.load('weights/{}_dlatent_avg.npy'.format(weights_name))\n",
    "\n",
    "# not using truncation\n",
    "generate_and_plot_images(generator, seed=6, w_avg=w_average)\n",
    "\n",
    "# using truncation 0.3\n",
    "generate_and_plot_images(generator, seed=6, w_avg=w_average, truncation_psi=0.3)\n",
    "\n",
    "#looks like the training was made also using cat memes :')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading church stylegan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = 'church' # church model trained by Nvidia\n",
    "\n",
    "# instantiating generator network\n",
    "generator = StyleGan2Generator(weights=weights_name, impl=impl, gpu=gpu)\n",
    "\n",
    "# loading w average\n",
    "w_average = np.load('weights/{}_dlatent_avg.npy'.format(weights_name))\n",
    "\n",
    "# not using truncation\n",
    "generate_and_plot_images(generator, seed=1, w_avg=w_average)\n",
    "\n",
    "# using truncation 0.5\n",
    "generate_and_plot_images(generator, seed=1, w_avg=w_average, truncation_psi=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading horse stylegan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = 'horse' # church model trained by Nvidia\n",
    "\n",
    "# instantiating generator network\n",
    "generator = StyleGan2Generator(weights=weights_name, impl=impl, gpu=gpu)\n",
    "\n",
    "# loading w average\n",
    "w_average = np.load('weights/{}_dlatent_avg.npy'.format(weights_name))\n",
    "\n",
    "# not using truncation\n",
    "generate_and_plot_images(generator, seed=0, w_avg=w_average)\n",
    "\n",
    "# using truncation 0.5\n",
    "generate_and_plot_images(generator, seed=0, w_avg=w_average, truncation_psi=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new stylegan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 512 # output resolution, square image power of 2\n",
    "\n",
    "# instantiating generator network\n",
    "generator = StyleGan2Generator(resolution=resolution, impl=impl, gpu=gpu)\n",
    "\n",
    "generate_and_plot_images(generator, seed=10, w_avg=np.zeros(512,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load stylegan2 entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from STYLEGAN2.stylegan2 import StyleGan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = 'horse' # church model trained by Nvidia\n",
    "\n",
    "# instantiating stylegan2 model, generator and discriminator\n",
    "model = StyleGan2(weights=weights_name, impl=impl, gpu=gpu)\n",
    "\n",
    "seed = 0\n",
    "#getting random latent vectors\n",
    "rnd = np.random.RandomState(seed)\n",
    "z = rnd.randn(3, 512).astype('float32')\n",
    "\n",
    "# getting generator output\n",
    "out_image = model.generator(z)\n",
    "\n",
    "# getting discriminator output\n",
    "score = model.discriminator(out_image)\n",
    "\n",
    "#scores\n",
    "print(score)\n",
    "\n",
    "# loading w average\n",
    "w_average = np.load('weights/{}_dlatent_avg.npy'.format(weights_name))\n",
    "\n",
    "# not using truncation\n",
    "generate_and_plot_images(model.generator, seed=seed, w_avg=w_average)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tf",
   "language": "python",
   "display_name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
