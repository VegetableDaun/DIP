{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MvK8yfylwoiZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MvK8yfylwoiZ",
    "outputId": "92c399cc-8996-46e6-aa7f-e4d2895e1c8e"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdfdc9c",
   "metadata": {
    "id": "9cdfdc9c"
   },
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca4ca98d",
   "metadata": {
    "id": "ca4ca98d",
    "ExecuteTime": {
     "end_time": "2023-09-12T15:37:30.168147200Z",
     "start_time": "2023-09-12T15:37:22.938779900Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c5adb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2c5adb0",
    "outputId": "b1fb7e30-3de0-4fee-d36a-063f0f506c1e",
    "ExecuteTime": {
     "end_time": "2023-09-12T15:37:36.555903300Z",
     "start_time": "2023-09-12T15:37:34.223449800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ddf8f8",
   "metadata": {
    "id": "35ddf8f8"
   },
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd7b7c5",
   "metadata": {
    "id": "7bd7b7c5"
   },
   "outputs": [],
   "source": [
    "count_Test = 1164\n",
    "count_Valid = 1164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652c3ba",
   "metadata": {
    "id": "a652c3ba"
   },
   "outputs": [],
   "source": [
    "# Define path to the data directory\n",
    "#'/content/drive/Othercomputers/Ноутбук/3/Code/chest-xray-pneumonia/chest_xray'\n",
    "data_dir = Path('chest-xray-pneumonia/chest_xray')\n",
    "\n",
    "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
    "train_dir = data_dir / 'train'\n",
    "\n",
    "# Path to validation directory\n",
    "val_dir = data_dir / 'val'\n",
    "\n",
    "# Path to test directory\n",
    "test_dir = data_dir / 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c452f6",
   "metadata": {
    "id": "b7c452f6"
   },
   "source": [
    "# Forming Train, Val and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c3d4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "225c3d4a",
    "outputId": "1517f32a-9101-4df0-fca6-fc376b3663e0"
   },
   "outputs": [],
   "source": [
    "train_data = [] # The first collection for Train, Val, Test\n",
    "\n",
    "### Path to Train\n",
    "normal_cases_dir = train_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "\n",
    "for img in normal_cases:\n",
    "    train_data.append((img, 0, 0)) # The label for these cases will be 0\n",
    "\n",
    "for img in pneumonia_cases:\n",
    "    if 'bacteria' in str(img).lower(): # The label for these cases will be 1 if it's bacteria or 2 if it's viral\n",
    "        train_data.append((img, 1, 0))\n",
    "    else:     \n",
    "        train_data.append((img, 2, 0))\n",
    "\n",
    "### Path to Val \n",
    "normal_cases_dir = val_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "for img in normal_cases:\n",
    "    train_data.append((img, 0, 0)) # The label for these cases will be 0\n",
    "\n",
    "for img in pneumonia_cases:\n",
    "    if 'bacteria' in str(img).lower(): # The label for these cases will be 1 if it's bacteria or 2 if it's viral\n",
    "        train_data.append((img, 1, 0))\n",
    "    else:     \n",
    "        train_data.append((img, 2, 0))    \n",
    "                     \n",
    "### Path to Train \n",
    "normal_cases_dir = test_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "for img in normal_cases:\n",
    "    train_data.append((img, 0, 0)) # The label for these cases will be 0\n",
    "\n",
    "for img in pneumonia_cases:\n",
    "    if 'bacteria' in str(img).lower(): # The label for these cases will be 1 if it's bacteria or 2 if it's viral\n",
    "        train_data.append((img, 1, 0))\n",
    "    else:     \n",
    "        train_data.append((img, 2, 0))   \n",
    "\n",
    "# Delete dublicate      \n",
    "train_del = []\n",
    "#'/content/drive/Othercomputers/Ноутбук/3/Code/dublicate.json'\n",
    "with open('dublicate.json', 'r') as F:\n",
    "    check_list = json.load(F)\n",
    "        \n",
    "for i, j in check_list:\n",
    "    for x, y, z in train_data:\n",
    "        if i[i.rfind('/') + 1 :] in str(x):\n",
    "            train_del.append(train_data.index((x, y, z)))\n",
    "\n",
    "for i in train_del:\n",
    "    train_data.pop(i)\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list \n",
    "train_data = pd.DataFrame(train_data, columns=['image', 'label', 'add'], index=None)\n",
    "\n",
    "# Shuffle the data \n",
    "train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# Devide into Train, Val and Test\n",
    "test_data = train_data[:count_Test]\n",
    "valid_data = train_data[count_Test : count_Test + count_Valid].reset_index(drop=True)\n",
    "train_data = train_data[count_Test + count_Valid :].reset_index(drop=True)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4046d",
   "metadata": {
    "id": "8df4046d"
   },
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b838c8",
   "metadata": {
    "id": "b3b838c8"
   },
   "outputs": [],
   "source": [
    "add_labels= {0 : 0, 1 : 0, 2 : 0}\n",
    "seq = A.Compose([\n",
    "    A.HorizontalFlip(), # horizontal flips\n",
    "    A.Affine(rotate=(-20, 20), p=0.50), # roatation\n",
    "    A.RandomBrightnessContrast(p=0.20) #random brightness\n",
    "                ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38022b16",
   "metadata": {
    "id": "38022b16"
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a98d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "id": "3b0a98d9",
    "outputId": "0f5dca24-a6d5-4a86-b258-5f49ffc92725"
   },
   "outputs": [],
   "source": [
    "# Get the counts for each class\n",
    "cases_count = train_data['label'].value_counts()\n",
    "print(cases_count)\n",
    "\n",
    "# Plot the results \n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x = cases_count.index, y = cases_count.values)\n",
    "plt.title('Число образцов', fontsize=14)\n",
    "plt.xlabel('Тип образца', fontsize=12)\n",
    "plt.ylabel('Число', fontsize=12)\n",
    "plt.xticks(range(len(cases_count.index)), ['Нормальное состояние (0)', 'Бактериальная пневмония (1)', 'Вирусная пневмония (2)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c122a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "713c122a",
    "outputId": "b5f45c39-a26e-42c7-8bcf-fbb55fd38dc4"
   },
   "outputs": [],
   "source": [
    "# Get few samples for both the classes\n",
    "normal_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\n",
    "bacteria_samples = (train_data[train_data['label']==1]['image'].iloc[:5]).tolist()\n",
    "viral_samples = (train_data[train_data['label']==2]['image'].iloc[:5]).tolist()\n",
    "\n",
    "# Concat the data in a single list and del the above three list\n",
    "samples = normal_samples + bacteria_samples + viral_samples\n",
    "del bacteria_samples, normal_samples, viral_samples\n",
    "\n",
    "# Plot the data \n",
    "f, ax = plt.subplots(3,5, figsize=(30,10))\n",
    "for i in range(15):\n",
    "    img = imread(samples[i])\n",
    "    ax[i//5, i%5].imshow(img, cmap='gray')\n",
    "    \n",
    "    if i<5:\n",
    "        ax[i//5, i%5].set_title(\"Нормальное состояние\")\n",
    "    elif 5 <= i < 10:\n",
    "        ax[i//5, i%5].set_title(\"Бактериальная пневмония\")\n",
    "    else:\n",
    "        ax[i//5, i%5].set_title(\"Вирусная пневмония\")\n",
    "    \n",
    "    ax[i//5, i%5].axis('off')\n",
    "    ax[i//5, i%5].set_aspect('auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9a4f7",
   "metadata": {
    "id": "47a9a4f7"
   },
   "source": [
    "# Uploading Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b617b06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b617b06",
    "outputId": "10e85be4-cd39-400e-a447-1fbd27b080f4"
   },
   "outputs": [],
   "source": [
    "# increase Val\n",
    "valid_data = increase(valid_data, add_labels=add_labels)\n",
    "\n",
    "# Preparing valid data\n",
    "if 'seq' not in globals():\n",
    "    valid_data = map(Conv, valid_data['image'].values, valid_data['label'].values)\n",
    "else:\n",
    "    valid_data_0 = map(Conv, valid_data[valid_data['add'] == 0]['image'].values, \n",
    "                     valid_data[valid_data['add'] == 0]['label'].values)\n",
    "    \n",
    "    valid_data_1 = map(Conv, valid_data[valid_data['add'] == 1]['image'].values, \n",
    "                     valid_data[valid_data['add'] == 1]['label'].values)\n",
    "    \n",
    "    valid_data = list(valid_data_0)\n",
    "    for img, label in valid_data_1:\n",
    "        valid_data.append((seq(image=img)['image'], label))\n",
    "    \n",
    "    #F = lambda img, label: (seq(imgage=img)['image'], label)\n",
    "    #valid_data_1 = map(F, list(valid_data_1))\n",
    "    \n",
    "valid = []\n",
    "valid_labels = []\n",
    "\n",
    "for i, j in valid_data:\n",
    "    valid.append(i.astype(np.float32)/255.)\n",
    "    valid_labels.append(j)\n",
    "\n",
    "# Convert the list into numpy arrays\n",
    "valid_data = np.array(valid)\n",
    "valid_labels = np.array(valid_labels)\n",
    "\n",
    "def shuffle(x, y):\n",
    "    p = np.random.permutation(len(y))\n",
    "    return x[p], y[p]\n",
    "\n",
    "valid_data, valid_labels = shuffle(valid_data, valid_labels)\n",
    "\n",
    "print(\"Total number of validation examples: \", valid_data.shape)\n",
    "print(\"Total number of labels:\", valid_labels.shape)\n",
    "\n",
    "del valid, valid_data_0, valid_data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46295c6",
   "metadata": {
    "id": "b46295c6"
   },
   "source": [
    "# MODEL cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e38ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e0e38ec",
    "outputId": "20481b03-238f-4778-e476-71c4c8c1ea60"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_channels = 3\n",
    "num_classes = 3\n",
    "image_size = 224\n",
    "latent_dim = 128\n",
    "\n",
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93ca5654964db91f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Discriminator.summary()\n",
    "Generator.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c35e7894"
  },
  {
   "cell_type": "markdown",
   "id": "701cd1ed",
   "metadata": {
    "id": "701cd1ed"
   },
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b32c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff8b32c4",
    "outputId": "8d062a80-ac01-4b0f-b541-864bee1cb5bb"
   },
   "outputs": [],
   "source": [
    "# Get a train data generator\n",
    "dataset = data_gen(data=train_data, batch_size=batch_size, Aug=seq, add_labels=add_labels)\n",
    "\n",
    "# Define the number of training steps\n",
    "nb_train_steps = 0\n",
    "for i in range(3):\n",
    "    nb_train_steps += (add_labels[i] + 1) * cases_count[i]\n",
    "\n",
    "nb_epochs = 300\n",
    "nb_train_steps //= batch_size\n",
    "\n",
    "print(\"Number of training and validation steps: {}\".format(nb_train_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IyagLz7zZqLw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IyagLz7zZqLw",
    "outputId": "d248528f-ae30-4ab1-89fd-1aaac1cb0dcc"
   },
   "outputs": [],
   "source": [
    "Discriminator = keras.models.load_model('/content/drive/Othercomputers/Ноутбук/3/Code/train_models/Discriminator.hdf5')\n",
    "Generator = keras.models.load_model('/content/drive/Othercomputers/Ноутбук/3/Code/train_models/Generator.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2552040",
   "metadata": {
    "id": "d2552040"
   },
   "outputs": [],
   "source": [
    "cond_gan = ConditionalGAN(discriminator=Discriminator, generator=Generator, latent_dim=latent_dim)\n",
    "\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy()\n",
    "    )\n",
    "\n",
    "data = tf.data.Dataset.from_generator(\n",
    "            lambda: data_gen(data=train_data, batch_size=batch_size, Aug=seq, add_labels=add_labels),\n",
    "            output_types= (tf.float32, tf.float32),\n",
    "            output_shapes= ((batch_size,224, 224, 3),(batch_size,3))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f24ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5b6f24ce",
    "outputId": "9ef84e5b-b872-4770-94ac-9c272e419ad5"
   },
   "outputs": [],
   "source": [
    "history_cGAN = cond_gan.fit(data, epochs=nb_epochs, steps_per_epoch=nb_train_steps, callbacks=[CustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U7O_uhSVG36C",
   "metadata": {
    "id": "U7O_uhSVG36C"
   },
   "outputs": [],
   "source": [
    "loss_g = history_cGAN.history[\"g_loss\"]\n",
    "loss_d = history_cGAN.history[\"d_loss\"]\n",
    "epochs = range(1, len(loss_g) + 1)\n",
    "plt.plot(epochs, loss_g, \"b\", label=\"Потери на этапе обучения генератора\")\n",
    "plt.plot(epochs, loss_d, \"g\", label=\"Потери на этапе обучения дискриминатора\")\n",
    "plt.title(\"Потери на этапах обучения\")\n",
    "plt.xlabel(\"Эпохи\")\n",
    "plt.ylabel(\"Потери\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dfab4c",
   "metadata": {
    "id": "84dfab4c"
   },
   "source": [
    "## Save GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b371d35",
   "metadata": {
    "id": "0b371d35"
   },
   "outputs": [],
   "source": [
    "GAN = cond_gan.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7af33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48c7af33",
    "outputId": "415ba85f-3f74-43af-882e-fa836a99b5f4"
   },
   "outputs": [],
   "source": [
    "def interpolate(gen, examples, numbers):\n",
    "    # Sample noise for the interpolation.\n",
    "    interpolation_noise = tf.random.normal(shape=(numbers * len(examples), latent_dim))\n",
    "    \n",
    "    # One_hote coder\n",
    "    repeats = [numbers, numbers, numbers]\n",
    "    one_hot_labels = np.repeat(examples, repeats)\n",
    "    one_hot_labels = keras.utils.to_categorical(one_hot_labels, num_classes)\n",
    "    \n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = tf.concat([interpolation_noise, one_hot_labels], 1)\n",
    "    fake = gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n",
    "\n",
    "examples = [0, 1, 2]\n",
    "\n",
    "fake_images = interpolate(GAN, examples, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9371b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "39a9371b",
    "outputId": "13be5e2b-ce9d-4c37-b0a0-06230beaa3d6"
   },
   "outputs": [],
   "source": [
    "print(fake_images.shape)\n",
    "\n",
    "# Plot the data \n",
    "f, ax = plt.subplots(3,5, figsize=(30,20))\n",
    "for i in range(15):\n",
    "    ax[i//5, i%5].imshow(fake_images[i], cmap='gray')\n",
    "\n",
    "    if i<5:\n",
    "        ax[i//5, i%5].set_title(\"Normal\")\n",
    "    elif 5 <= i < 10:\n",
    "        ax[i//5, i%5].set_title(\"Bacteria\")\n",
    "    else:\n",
    "        ax[i//5, i%5].set_title(\"Viral\")\n",
    "    \n",
    "    ax[i//5, i%5].axis('off')\n",
    "    ax[i//5, i%5].set_aspect('auto')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
