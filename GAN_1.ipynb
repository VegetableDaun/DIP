{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MvK8yfylwoiZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MvK8yfylwoiZ",
    "outputId": "92c399cc-8996-46e6-aa7f-e4d2895e1c8e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdfdc9c",
   "metadata": {
    "id": "9cdfdc9c"
   },
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca4ca98d",
   "metadata": {
    "id": "ca4ca98d",
    "ExecuteTime": {
     "end_time": "2023-09-12T15:37:30.168147200Z",
     "start_time": "2023-09-12T15:37:22.938779900Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c5adb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2c5adb0",
    "outputId": "b1fb7e30-3de0-4fee-d36a-063f0f506c1e",
    "ExecuteTime": {
     "end_time": "2023-09-12T15:37:36.555903300Z",
     "start_time": "2023-09-12T15:37:34.223449800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ddf8f8",
   "metadata": {
    "id": "35ddf8f8"
   },
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd7b7c5",
   "metadata": {
    "id": "7bd7b7c5"
   },
   "outputs": [],
   "source": [
    "count_Test = 1164\n",
    "count_Valid = 1164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652c3ba",
   "metadata": {
    "id": "a652c3ba"
   },
   "outputs": [],
   "source": [
    "# Define path to the data directory\n",
    "#'/content/drive/Othercomputers/Ноутбук/3/Code/chest-xray-pneumonia/chest_xray'\n",
    "data_dir = Path('chest-xray-pneumonia/chest_xray')\n",
    "\n",
    "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
    "train_dir = data_dir / 'train'\n",
    "\n",
    "# Path to validation directory\n",
    "val_dir = data_dir / 'val'\n",
    "\n",
    "# Path to test directory\n",
    "test_dir = data_dir / 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c452f6",
   "metadata": {
    "id": "b7c452f6"
   },
   "source": [
    "# Forming Train, Val and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c3d4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "225c3d4a",
    "outputId": "1517f32a-9101-4df0-fca6-fc376b3663e0"
   },
   "outputs": [],
   "source": [
    "train_data = [] # The first collection for Train, Val, Test\n",
    "\n",
    "### Path to Train\n",
    "normal_cases_dir = train_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "\n",
    "for img in normal_cases:\n",
    "    train_data.append((img, 0, 0)) # The label for these cases will be 0\n",
    "\n",
    "for img in pneumonia_cases:\n",
    "    if 'bacteria' in str(img).lower(): # The label for these cases will be 1 if it's bacteria or 2 if it's viral\n",
    "        train_data.append((img, 1, 0))\n",
    "    else:     \n",
    "        train_data.append((img, 2, 0))\n",
    "\n",
    "### Path to Val \n",
    "normal_cases_dir = val_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "for img in normal_cases:\n",
    "    train_data.append((img, 0, 0)) # The label for these cases will be 0\n",
    "\n",
    "for img in pneumonia_cases:\n",
    "    if 'bacteria' in str(img).lower(): # The label for these cases will be 1 if it's bacteria or 2 if it's viral\n",
    "        train_data.append((img, 1, 0))\n",
    "    else:     \n",
    "        train_data.append((img, 2, 0))    \n",
    "                     \n",
    "### Path to Train \n",
    "normal_cases_dir = test_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "for img in normal_cases:\n",
    "    train_data.append((img, 0, 0)) # The label for these cases will be 0\n",
    "\n",
    "for img in pneumonia_cases:\n",
    "    if 'bacteria' in str(img).lower(): # The label for these cases will be 1 if it's bacteria or 2 if it's viral\n",
    "        train_data.append((img, 1, 0))\n",
    "    else:     \n",
    "        train_data.append((img, 2, 0))   \n",
    "\n",
    "# Delete dublicate      \n",
    "train_del = []\n",
    "#'/content/drive/Othercomputers/Ноутбук/3/Code/dublicate.json'\n",
    "with open('dublicate.json', 'r') as F:\n",
    "    check_list = json.load(F)\n",
    "        \n",
    "for i, j in check_list:\n",
    "    for x, y, z in train_data:\n",
    "        if i[i.rfind('/') + 1 :] in str(x):\n",
    "            train_del.append(train_data.index((x, y, z)))\n",
    "\n",
    "for i in train_del:\n",
    "    train_data.pop(i)\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list \n",
    "train_data = pd.DataFrame(train_data, columns=['image', 'label', 'add'], index=None)\n",
    "\n",
    "# Shuffle the data \n",
    "train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# Devide into Train, Val and Test\n",
    "test_data = train_data[:count_Test]\n",
    "valid_data = train_data[count_Test : count_Test + count_Valid].reset_index(drop=True)\n",
    "train_data = train_data[count_Test + count_Valid :].reset_index(drop=True)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5777a634",
   "metadata": {
    "id": "5777a634"
   },
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4362443",
   "metadata": {
    "id": "a4362443"
   },
   "outputs": [],
   "source": [
    "def Conv(img, label):\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    \n",
    "    if img.shape[2] == 1:\n",
    "        img = np.dstack([img, img, img])\n",
    "        \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    label = to_categorical(label, num_classes=3)\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd4dd2",
   "metadata": {
    "id": "8cdd4dd2"
   },
   "outputs": [],
   "source": [
    "def increase(Data, add_labels):\n",
    "    add = pd.DataFrame()\n",
    "    #if Data.iloc[i]['label'] in add_labels:\n",
    "    for i in range(len(Data)):\n",
    "        for _ in range(add_labels[Data.iloc[i]['label']]):\n",
    "            add = pd.concat([add, Data.iloc[[i]]])\n",
    "    \n",
    "    add = add.replace({'add': 0}, 1)\n",
    "    Data = pd.concat([Data, add]).reset_index(drop=True)\n",
    "    \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bec60f",
   "metadata": {
    "id": "78bec60f"
   },
   "outputs": [],
   "source": [
    "def data_gen(data, batch_size, Aug=None, add_labels=None, GEN=None, gen_labels=None, latent_dim=128):\n",
    "    if Aug != None and add_labels != {0: 0, 1: 0, 2: 0}:\n",
    "        data = increase(data, add_labels)\n",
    "\n",
    "    data = data.sample(frac=1.).reset_index(drop=True)  # Shuffle data\n",
    "\n",
    "    n = len(data)  # Get total number of samples in the data\n",
    "    indices = np.arange(n)  # Get a numpy array of all the indices of the input data\n",
    "    steps = n // batch_size  # Get numbers of steps\n",
    "\n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size, 3), dtype=np.float32)\n",
    "\n",
    "    i = 0  # Initialize a counter\n",
    "    np.random.shuffle(indices)  # Random indices\n",
    "    while True:\n",
    "        # Get the next batch\n",
    "        count = 0\n",
    "        next_batch = indices[i * batch_size: (i + 1) * batch_size]\n",
    "        for idx in next_batch:\n",
    "            sample = data.iloc[int(idx)]\n",
    "            if sample['add'] == 0:\n",
    "                img, label = Conv(sample['image'], sample['label'])  # generating samples\n",
    "\n",
    "                batch_data[count] = img.astype(np.float32) / 255.\n",
    "                batch_labels[count] = label\n",
    "\n",
    "                count += 1\n",
    "            else:\n",
    "                img, label = Conv(sample['image'], sample['label'])  # generating more samples\n",
    "\n",
    "                batch_data[count] = Aug(image=img)['image'].astype(np.float32) / 255.\n",
    "                batch_labels[count] = label\n",
    "\n",
    "                count += 1\n",
    "\n",
    "        if GEN != None:\n",
    "            if gen_labels == None:\n",
    "                interpolation_noise = tf.random.normal(shape=(batch_data.shape[0], latent_dim))\n",
    "                gen_batch_labels = batch_labels\n",
    "            else:\n",
    "                interpolation_noise = tf.random.normal(shape=(sum(gen_labels.values()), latent_dim))\n",
    "                gen_batch_labels = np.repeat(list(gen_labels.keys()), list(gen_labels.values()))\n",
    "                gen_batch_labels = keras.utils.to_categorical(gen_batch_labels, num_classes=3)\n",
    "\n",
    "            interpolation_noise_labels = tf.concat([interpolation_noise, gen_batch_labels], axis=1)\n",
    "            GEN_images = GEN.predict(interpolation_noise_labels)\n",
    "\n",
    "            batch_data = np.vstack((batch_data, GEN_images))\n",
    "            batch_labels = np.vstack((batch_labels, gen_batch_labels))\n",
    "\n",
    "        yield batch_data, batch_labels\n",
    "\n",
    "        i += 1\n",
    "        if i == steps:\n",
    "            i = 0\n",
    "            np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4046d",
   "metadata": {
    "id": "8df4046d"
   },
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b838c8",
   "metadata": {
    "id": "b3b838c8"
   },
   "outputs": [],
   "source": [
    "add_labels= {0 : 0, 1 : 0, 2 : 0}\n",
    "seq = A.Compose([\n",
    "    A.HorizontalFlip(), # horizontal flips\n",
    "    A.Affine(rotate=(-20, 20), p=0.50), # roatation\n",
    "    A.RandomBrightnessContrast(p=0.20) #random brightness\n",
    "                ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38022b16",
   "metadata": {
    "id": "38022b16"
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a98d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "id": "3b0a98d9",
    "outputId": "0f5dca24-a6d5-4a86-b258-5f49ffc92725"
   },
   "outputs": [],
   "source": [
    "# Get the counts for each class\n",
    "cases_count = train_data['label'].value_counts()\n",
    "print(cases_count)\n",
    "\n",
    "# Plot the results \n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x = cases_count.index, y = cases_count.values)\n",
    "plt.title('Число образцов', fontsize=14)\n",
    "plt.xlabel('Тип образца', fontsize=12)\n",
    "plt.ylabel('Число', fontsize=12)\n",
    "plt.xticks(range(len(cases_count.index)), ['Нормальное состояние (0)', 'Бактериальная пневмония (1)', 'Вирусная пневмония (2)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c122a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "713c122a",
    "outputId": "b5f45c39-a26e-42c7-8bcf-fbb55fd38dc4"
   },
   "outputs": [],
   "source": [
    "# Get few samples for both the classes\n",
    "normal_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\n",
    "bacteria_samples = (train_data[train_data['label']==1]['image'].iloc[:5]).tolist()\n",
    "viral_samples = (train_data[train_data['label']==2]['image'].iloc[:5]).tolist()\n",
    "\n",
    "# Concat the data in a single list and del the above three list\n",
    "samples = normal_samples + bacteria_samples + viral_samples\n",
    "del bacteria_samples, normal_samples, viral_samples\n",
    "\n",
    "# Plot the data \n",
    "f, ax = plt.subplots(3,5, figsize=(30,10))\n",
    "for i in range(15):\n",
    "    img = imread(samples[i])\n",
    "    ax[i//5, i%5].imshow(img, cmap='gray')\n",
    "    \n",
    "    if i<5:\n",
    "        ax[i//5, i%5].set_title(\"Нормальное состояние\")\n",
    "    elif 5 <= i < 10:\n",
    "        ax[i//5, i%5].set_title(\"Бактериальная пневмония\")\n",
    "    else:\n",
    "        ax[i//5, i%5].set_title(\"Вирусная пневмония\")\n",
    "    \n",
    "    ax[i//5, i%5].axis('off')\n",
    "    ax[i//5, i%5].set_aspect('auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9a4f7",
   "metadata": {
    "id": "47a9a4f7"
   },
   "source": [
    "# Uploading Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b617b06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b617b06",
    "outputId": "10e85be4-cd39-400e-a447-1fbd27b080f4"
   },
   "outputs": [],
   "source": [
    "# increase Val\n",
    "valid_data = increase(valid_data, add_labels=add_labels)\n",
    "\n",
    "# Preparing valid data\n",
    "if 'seq' not in globals():\n",
    "    valid_data = map(Conv, valid_data['image'].values, valid_data['label'].values)\n",
    "else:\n",
    "    valid_data_0 = map(Conv, valid_data[valid_data['add'] == 0]['image'].values, \n",
    "                     valid_data[valid_data['add'] == 0]['label'].values)\n",
    "    \n",
    "    valid_data_1 = map(Conv, valid_data[valid_data['add'] == 1]['image'].values, \n",
    "                     valid_data[valid_data['add'] == 1]['label'].values)\n",
    "    \n",
    "    valid_data = list(valid_data_0)\n",
    "    for img, label in valid_data_1:\n",
    "        valid_data.append((seq(image=img)['image'], label))\n",
    "    \n",
    "    #F = lambda img, label: (seq(imgage=img)['image'], label)\n",
    "    #valid_data_1 = map(F, list(valid_data_1))\n",
    "    \n",
    "valid = []\n",
    "valid_labels = []\n",
    "\n",
    "for i, j in valid_data:\n",
    "    valid.append(i.astype(np.float32)/255.)\n",
    "    valid_labels.append(j)\n",
    "\n",
    "# Convert the list into numpy arrays\n",
    "valid_data = np.array(valid)\n",
    "valid_labels = np.array(valid_labels)\n",
    "\n",
    "def shuffle(x, y):\n",
    "    p = np.random.permutation(len(y))\n",
    "    return x[p], y[p]\n",
    "\n",
    "valid_data, valid_labels = shuffle(valid_data, valid_labels)\n",
    "\n",
    "print(\"Total number of validation examples: \", valid_data.shape)\n",
    "print(\"Total number of labels:\", valid_labels.shape)\n",
    "\n",
    "del valid, valid_data_0, valid_data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46295c6",
   "metadata": {
    "id": "b46295c6"
   },
   "source": [
    "# MODEL cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e38ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e0e38ec",
    "outputId": "20481b03-238f-4778-e476-71c4c8c1ea60"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_channels = 3\n",
    "num_classes = 3\n",
    "image_size = 224\n",
    "latent_dim = 128\n",
    "\n",
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e7894",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c35e7894",
    "outputId": "b5a65da3-19fb-4c2c-adac-29bcf2019787"
   },
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "input_img = layers.Input(shape=(224, 224, discriminator_in_channels), name='ImageInput')\n",
    "    \n",
    "x = layers.Conv2D(32, (3, 3), activation=layers.LeakyReLU(alpha=0.2), strides = (2, 2), padding=\"same\", name='Conv2d_1')(input_img)\n",
    "x = layers.BatchNormalization(name='Batch_1')(x)\n",
    "#x = layers.Dropout(0.2)(x)\n",
    "\n",
    "##x = layers.Conv2D(32, (1, 1), activation=layers.LeakyReLU(alpha=0.2), strides = (2, 2), padding=\"same\", name='Conv2d_2')(input_img)\n",
    "##x = layers.BatchNormalization(name='Batch_2')(x)\n",
    "#x = layers.Dropout(0.2)(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation=layers.LeakyReLU(alpha=0.2), strides = (2, 2), padding=\"same\", name='Conv2d_2')(x)\n",
    "x = layers.BatchNormalization(name='Batch_2')(x)\n",
    "#x = layers.Dropout(0.2)(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation=layers.LeakyReLU(alpha=0.2), strides = (2, 2), padding=\"same\", name='Conv2d_3')(x)\n",
    "x = layers.BatchNormalization(name='Batch_3')(x)\n",
    "#x = layers.Dropout(0.2)(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), activation=layers.LeakyReLU(alpha=0.2), strides = (2, 2), padding=\"same\", name='Conv2d_4')(x)\n",
    "x = layers.BatchNormalization(name='Batch_4')(x)\n",
    "#x = layers.Dropout(0.2)(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), activation=layers.LeakyReLU(alpha=0.2), strides = (2, 2), padding=\"same\", name='Conv2d_5')(x)\n",
    "x = layers.BatchNormalization(name='Batch_5')(x)\n",
    "#x = layers.Dropout(0.2)(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3, 3), activation=layers.LeakyReLU(alpha=0.2), strides = (2, 2), padding=\"same\", name='Conv2d_6')(x)\n",
    "x = layers.BatchNormalization(name='Batch_6')(x)\n",
    "#x = layers.Dropout(0.2)(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3, 3), activation=layers.LeakyReLU(alpha=0.2), strides = (1, 1), padding=\"same\", name='Conv2d_7')(x)\n",
    "x = layers.BatchNormalization(name='Batch_7')(x)\n",
    "#x = layers.Dropout(0.2)(x)\n",
    "\n",
    "x = layers.Flatten(name='flatten')(x)\n",
    "\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Dense(1, activation='sigmoid', name='fc_1')(x)\n",
    "\n",
    "Discriminator = keras.models.Model(inputs=input_img, outputs=x, name='Discriminator')\n",
    "    \n",
    "    \n",
    "    \n",
    "# Create the generator.\n",
    "input_img = layers.Input(shape=(generator_in_channels), name='NoiseInput')\n",
    "\n",
    "x = layers.Dense(14 * 14 * generator_in_channels, activation=layers.LeakyReLU(alpha=0.2), name='fc_1')(input_img) \n",
    "x = layers.Reshape((14, 14, generator_in_channels))(x)\n",
    "x = layers.BatchNormalization(name='Batch_1')(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding=\"same\", activation=layers.LeakyReLU(alpha=0.2), name='Conv2DTrans_1')(x)\n",
    "x = layers.BatchNormalization(name='Batch_2')(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding=\"same\", activation=layers.LeakyReLU(alpha=0.2), name='Conv2DTrans_2')(x)\n",
    "x = layers.BatchNormalization(name='Batch_3')(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\", activation=layers.LeakyReLU(alpha=0.2), name='Conv2DTrans_3')(x)\n",
    "x = layers.BatchNormalization(name='Batch_4')(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding=\"same\", activation=layers.LeakyReLU(alpha=0.2), name='Conv2DTrans_4')(x)\n",
    "x = layers.BatchNormalization(name='Batch_5')(x)\n",
    "\n",
    "x = layers.Conv2D(3, (5, 5), padding=\"same\", activation=\"sigmoid\", name='Conv2D_1')(x)\n",
    "\n",
    "Generator = keras.models.Model(inputs=input_img, outputs=x, name='Generator')\n",
    "\n",
    "\n",
    "\n",
    "# Model\n",
    "Discriminator.summary()\n",
    "Generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c59a3",
   "metadata": {
    "id": "ac0c59a3"
   },
   "source": [
    "## Class GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57gri_oFBOP",
   "metadata": {
    "id": "e57gri_oFBOP"
   },
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antj5-oWJGKk",
   "metadata": {
    "id": "antj5-oWJGKk"
   },
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "#path=Path().resolve()\n",
    "    def __init__(self, num_save=5, path=Path('/content/drive/Othercomputers/Ноутбук/3/Code'), noise='noise.json'):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.num_save = num_save\n",
    "        self.path = path\n",
    "\n",
    "        with open(self.path / noise, mode='r') as F:\n",
    "            self.noise = np.array(json.load(F))\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        if os.path.isfile(self.path / 'train_models/metrics.json'):\n",
    "            with open(self.path / 'train_models/metrics.json', mode='r') as F:\n",
    "                feeds = dict(json.load(F))\n",
    "                completed_steps = max(map(int, feeds.keys()))\n",
    "                while (completed_steps %  self.num_save != 0):\n",
    "                    del feeds[str(completed_steps)]\n",
    "                    completed_steps -= 1\n",
    "            if completed_steps != 0:\n",
    "                with open(self.path / 'train_models/metrics.json', mode='w') as F:\n",
    "                    json.dump(feeds, F)\n",
    "            else:\n",
    "                os.remove(self.path / 'train_models/metrics.json')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        add_value = {}\n",
    "        if not os.path.isfile(self.path / 'train_models/metrics.json'):\n",
    "            with open(self.path / 'train_models/metrics.json', mode='w') as F:\n",
    "                add_value[1] = logs\n",
    "                json.dump(add_value, F)\n",
    "        else:\n",
    "            with open(self.path / 'train_models/metrics.json', mode='r') as F:\n",
    "                feeds = dict(json.load(F))\n",
    "                feeds_keys = map(int, feeds.keys())\n",
    "                add_key = max(feeds_keys) + 1\n",
    "                feeds[add_key] = logs\n",
    "            with open(self.path / 'train_models/metrics.json', mode='w') as F:\n",
    "                json.dump(feeds, F)\n",
    "\n",
    "        if (epoch + 1) % self.num_save == 0:\n",
    "            self.model.discriminator.save(self.path / 'train_models/Discriminator.hdf5')\n",
    "            self.model.generator.save(self.path / 'train_models/Generator.hdf5')\n",
    "\n",
    "            img = np.array(self.model.generator(self.noise))[0]\n",
    "            img = np.round(img * 255)\n",
    "            img = img.astype(np.uint8)\n",
    "            img = Image.fromarray(img)\n",
    "            img.save(self.path / ('train_models/Image/Epoch_' + str(add_key) + '.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701cd1ed",
   "metadata": {
    "id": "701cd1ed"
   },
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b32c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff8b32c4",
    "outputId": "8d062a80-ac01-4b0f-b541-864bee1cb5bb"
   },
   "outputs": [],
   "source": [
    "# Get a train data generator\n",
    "dataset = data_gen(data=train_data, batch_size=batch_size, Aug=seq, add_labels=add_labels)\n",
    "\n",
    "# Define the number of training steps\n",
    "nb_train_steps = 0\n",
    "for i in range(3):\n",
    "    nb_train_steps += (add_labels[i] + 1) * cases_count[i]\n",
    "\n",
    "nb_epochs = 300\n",
    "nb_train_steps //= batch_size\n",
    "\n",
    "print(\"Number of training and validation steps: {}\".format(nb_train_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IyagLz7zZqLw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IyagLz7zZqLw",
    "outputId": "d248528f-ae30-4ab1-89fd-1aaac1cb0dcc"
   },
   "outputs": [],
   "source": [
    "Discriminator = keras.models.load_model('/content/drive/Othercomputers/Ноутбук/3/Code/train_models/Discriminator.hdf5')\n",
    "Generator = keras.models.load_model('/content/drive/Othercomputers/Ноутбук/3/Code/train_models/Generator.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2552040",
   "metadata": {
    "id": "d2552040"
   },
   "outputs": [],
   "source": [
    "cond_gan = ConditionalGAN(discriminator=Discriminator, generator=Generator, latent_dim=latent_dim)\n",
    "\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy()\n",
    "    )\n",
    "\n",
    "data = tf.data.Dataset.from_generator(\n",
    "            lambda: data_gen(data=train_data, batch_size=batch_size, Aug=seq, add_labels=add_labels),\n",
    "            output_types= (tf.float32, tf.float32),\n",
    "            output_shapes= ((batch_size,224, 224, 3),(batch_size,3))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f24ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5b6f24ce",
    "outputId": "9ef84e5b-b872-4770-94ac-9c272e419ad5"
   },
   "outputs": [],
   "source": [
    "history_cGAN = cond_gan.fit(data, epochs=nb_epochs, steps_per_epoch=nb_train_steps, callbacks=[CustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U7O_uhSVG36C",
   "metadata": {
    "id": "U7O_uhSVG36C"
   },
   "outputs": [],
   "source": [
    "loss_g = history_cGAN.history[\"g_loss\"]\n",
    "loss_d = history_cGAN.history[\"d_loss\"]\n",
    "epochs = range(1, len(loss_g) + 1)\n",
    "plt.plot(epochs, loss_g, \"b\", label=\"Потери на этапе обучения генератора\")\n",
    "plt.plot(epochs, loss_d, \"g\", label=\"Потери на этапе обучения дискриминатора\")\n",
    "plt.title(\"Потери на этапах обучения\")\n",
    "plt.xlabel(\"Эпохи\")\n",
    "plt.ylabel(\"Потери\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dfab4c",
   "metadata": {
    "id": "84dfab4c"
   },
   "source": [
    "## Save GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b371d35",
   "metadata": {
    "id": "0b371d35"
   },
   "outputs": [],
   "source": [
    "GAN = cond_gan.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7af33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48c7af33",
    "outputId": "415ba85f-3f74-43af-882e-fa836a99b5f4"
   },
   "outputs": [],
   "source": [
    "def interpolate(gen, examples, numbers):\n",
    "    # Sample noise for the interpolation.\n",
    "    interpolation_noise = tf.random.normal(shape=(numbers * len(examples), latent_dim))\n",
    "    \n",
    "    # One_hote coder\n",
    "    repeats = [numbers, numbers, numbers]\n",
    "    one_hot_labels = np.repeat(examples, repeats)\n",
    "    one_hot_labels = keras.utils.to_categorical(one_hot_labels, num_classes)\n",
    "    \n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = tf.concat([interpolation_noise, one_hot_labels], 1)\n",
    "    fake = gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n",
    "\n",
    "examples = [0, 1, 2]\n",
    "\n",
    "fake_images = interpolate(GAN, examples, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9371b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "39a9371b",
    "outputId": "13be5e2b-ce9d-4c37-b0a0-06230beaa3d6"
   },
   "outputs": [],
   "source": [
    "print(fake_images.shape)\n",
    "\n",
    "# Plot the data \n",
    "f, ax = plt.subplots(3,5, figsize=(30,20))\n",
    "for i in range(15):\n",
    "    ax[i//5, i%5].imshow(fake_images[i], cmap='gray')\n",
    "\n",
    "    if i<5:\n",
    "        ax[i//5, i%5].set_title(\"Normal\")\n",
    "    elif 5 <= i < 10:\n",
    "        ax[i//5, i%5].set_title(\"Bacteria\")\n",
    "    else:\n",
    "        ax[i//5, i%5].set_title(\"Viral\")\n",
    "    \n",
    "    ax[i//5, i%5].axis('off')\n",
    "    ax[i//5, i%5].set_aspect('auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a24ad",
   "metadata": {
    "id": "c54a24ad"
   },
   "source": [
    "## Load GEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b32887",
   "metadata": {
    "id": "f5b32887"
   },
   "outputs": [],
   "source": [
    "GEN = keras.models.load_model('train_models/Generator.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c594b",
   "metadata": {
    "id": "590c594b"
   },
   "source": [
    "# MODEL CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0331118e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0331118e",
    "outputId": "f933fe27-a9ff-487b-9edc-2e3e4cc805e1"
   },
   "outputs": [],
   "source": [
    "# Create the CNN\n",
    "input_img = layers.Input(shape=(224,224,3), name='ImageInput')\n",
    "    \n",
    "x = layers.Conv2D(32, (3,3), activation='selu', name='Conv2d_1')(input_img)\n",
    "#x = layers.BatchNormalization(name='bn_1')(x)\n",
    "x = layers.MaxPooling2D((2,2), name='max_pool_1')(x)\n",
    "\n",
    "x = layers.Conv2D(32, (3,3), activation='selu', name='Conv2d_2')(x)\n",
    "#x = layers.BatchNormalization(name='bn_2')(x)\n",
    "x = layers.MaxPooling2D((2,2), name='max_pool_2')(x)\n",
    "    \n",
    "x = layers.Conv2D(64, (3,3), activation='selu', name='Conv2d_3')(x)\n",
    "#x = layers.BatchNormalization(name='bn_3')(x)\n",
    "x = layers.MaxPooling2D((2,2), name='max_pool_3')(x)\n",
    "\n",
    "\n",
    "x = layers.Flatten(name='flatten')(x)\n",
    "\n",
    "x = layers.Dense(64, activation='selu', name='fc_1')(x)\n",
    "x = layers.Dropout(0.7, name='dropout_1')(x)\n",
    "\n",
    "x = layers.Dense(32, activation='selu', name='fc_2')(x)\n",
    "x = layers.Dropout(0.3, name='dropout_2')(x)\n",
    "\n",
    "x = layers.Dense(3, activation='softmax', name='fc_3')(x)\n",
    "\n",
    "Discriminator = keras.models.Model(inputs=input_img, outputs=x, name='CNN')\n",
    "    \n",
    "#kernel_regularizer='l2'\n",
    "    \n",
    "# Model\n",
    "Discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a0191f",
   "metadata": {
    "id": "a0a0191f"
   },
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af353d07",
   "metadata": {
    "id": "af353d07"
   },
   "outputs": [],
   "source": [
    "# CallBack\n",
    "#keras.callbacks.EarlyStopping(patience=5),\n",
    "my_callbacks = [keras.callbacks.ModelCheckpoint(filepath='best_model_CNN.hdf5', save_best_only=True, save_weights_only=True),\n",
    "               tf.keras.callbacks.CSVLogger('log.scv', separator=\",\", append=False)]\n",
    "\n",
    "# Optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Compile\n",
    "Discriminator.compile(loss='CategoricalCrossentropy', metrics=['accuracy'], optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d38da",
   "metadata": {
    "id": "9c4d38da"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_epochs = 20\n",
    "\n",
    "# Get a train data generator\n",
    "train_data_gen = data_gen(data=train_data, batch_size=batch_size, Aug=seq, add_labels=add_labels)\n",
    "\n",
    "# Define the number of training steps\n",
    "nb_train_steps = 0\n",
    "for i in range(3):\n",
    "    nb_train_steps += (add_labels[i] + 1) * cases_count[i]\n",
    "    \n",
    "nb_train_steps //= batch_size    \n",
    "print(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f6432",
   "metadata": {
    "id": "377f6432"
   },
   "outputs": [],
   "source": [
    "# # Fit the model\n",
    "\n",
    "history = Discriminator.fit(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
    "                   validation_data=(valid_data, valid_labels), callbacks=my_callbacks)\n",
    "# class_weight={0:2.0, 1:1, 2:2.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dc015a",
   "metadata": {
    "id": "d4dc015a"
   },
   "source": [
    "## Plots of loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b397f43",
   "metadata": {
    "id": "9b397f43"
   },
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Потери на этапе обучения\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Потери на этапе проверки\")\n",
    "plt.title(\"Потери на этапах обучения и проверки\")\n",
    "plt.xlabel(\"Эпохи\")\n",
    "plt.ylabel(\"Потери\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Точность на этапе обучения\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Точность на этапе проверки\")\n",
    "plt.title(\"Точность на этапах обучения и проверки\")\n",
    "plt.xlabel(\"Эпохи\")\n",
    "plt.ylabel(\"Точность\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7638c9e",
   "metadata": {
    "id": "b7638c9e"
   },
   "source": [
    "# Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf39f69",
   "metadata": {
    "id": "9bf39f69"
   },
   "outputs": [],
   "source": [
    "Discriminator.load_weights('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf1ec9",
   "metadata": {
    "id": "48bf1ec9"
   },
   "source": [
    "# Uploading Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c32fd16",
   "metadata": {
    "id": "8c32fd16"
   },
   "outputs": [],
   "source": [
    "# increase Test\n",
    "test_data = increase(test_data, add_labels=add_labels)\n",
    "\n",
    "# Preparing test data\n",
    "if 'seq' not in globals():\n",
    "    test_data = map(Conv, test_data['image'].values, test_data['label'].values)\n",
    "else:\n",
    "    test_data_0 = map(Conv, test_data[test_data['add'] == 0]['image'].values, \n",
    "                     test_data[test_data['add'] == 0]['label'].values)\n",
    "    \n",
    "    test_data_1 = map(Conv, test_data[test_data['add'] == 1]['image'].values, \n",
    "                     test_data[test_data['add'] == 1]['label'].values)\n",
    "    \n",
    "    test_data = list(test_data_0)\n",
    "    for img, label in test_data_1:\n",
    "        test_data.append((seq(image=img)['image'], label))\n",
    "        \n",
    "test = []\n",
    "test_labels = []\n",
    "\n",
    "for i, j in test_data:\n",
    "    test.append(i.astype(np.float32)/255.)\n",
    "    test_labels.append(j)\n",
    "\n",
    "# Convert the list into numpy arrays\n",
    "test_data = np.array(test)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "def shuffle(x, y):\n",
    "    p = np.random.permutation(len(y))\n",
    "    return x[p], y[p]\n",
    "\n",
    "test_data, test_labels = shuffle(test_data, test_labels)\n",
    "\n",
    "print(\"Total number of test examples: \", test_data.shape)\n",
    "print(\"Total number of labels:\", test_labels.shape)\n",
    "\n",
    "del test, test_data_0, test_data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76090c8",
   "metadata": {
    "id": "e76090c8"
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179fd3bb",
   "metadata": {
    "id": "179fd3bb"
   },
   "outputs": [],
   "source": [
    "# Evaluation on test dataset\n",
    "test_loss, test_score = Discriminator.evaluate(test_data, test_labels, batch_size=32)\n",
    "\n",
    "print()\n",
    "\n",
    "x_0 = 0\n",
    "x_1 = 0\n",
    "x_2 = 0\n",
    "for i in range(test_labels.shape[0]):\n",
    "    if test_labels[i][0]:\n",
    "        x_0 += 1\n",
    "    elif test_labels[i][1]:\n",
    "        x_1 += 1\n",
    "    else:\n",
    "        x_2 += 1\n",
    "        \n",
    "print(x_0, x_1, x_2, '- EXAMPLES')\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Loss on test set: \", test_loss)\n",
    "print(\"Accuracy on test set: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f6e5c1",
   "metadata": {
    "id": "88f6e5c1"
   },
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = Discriminator.predict(test_data, batch_size=16)\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "# Original labels\n",
    "orig_test_labels = np.argmax(test_labels, axis=-1)\n",
    "\n",
    "print(orig_test_labels.shape)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b03a3b7",
   "metadata": {
    "id": "8b03a3b7"
   },
   "source": [
    "# ConfusionMatrix and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcaf1a8",
   "metadata": {
    "id": "5dcaf1a8"
   },
   "outputs": [],
   "source": [
    "cm  = confusion_matrix(y_true=orig_test_labels, y_pred=preds)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(3), ['Normal', 'Bacteria', 'Viral'], fontsize=16)\n",
    "plt.yticks(range(3), ['Normal', 'Bacteria', 'Viral'], fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf1755",
   "metadata": {
    "id": "85bf1755"
   },
   "outputs": [],
   "source": [
    "# Calculate error rate \n",
    "accuracy = (cm[0][0] + cm[1][1] + cm[2][2]) / (sum(cm.ravel())) \n",
    "\n",
    "Recall_0 = cm[0][0] / (cm[0][0] + cm[1][0] + cm[2][0])\n",
    "Recall_1 = cm[1][1] / (cm[0][1] + cm[1][1] + cm[2][1])\n",
    "Recall_2 = cm[2][2] / (cm[0][2] + cm[1][2] + cm[2][2])\n",
    "\n",
    "Precision_0 = cm[0][0] / (cm[0][0] + cm[0][1] + cm[0][2])\n",
    "Precision_1 = cm[1][1] / (cm[1][0] + cm[1][1] + cm[1][2])\n",
    "Precision_2 = cm[2][2] / (cm[2][0] + cm[2][1] + cm[2][2])\n",
    "\n",
    "F_0 = 2 / (1 / Precision_0 + 1 / Recall_0)\n",
    "F_1 = 2 / (1 / Precision_1 + 1 / Recall_1)\n",
    "F_2 = 2 / (1 / Precision_2 + 1 / Recall_2)\n",
    "\n",
    "print(\"Accuracy of the Discriminator is {:.2f}\".format(accuracy))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Recall of the first class is {:.2f}\".format(Recall_0))\n",
    "print(\"Recall of the second class is {:.2f}\".format(Recall_1))\n",
    "print(\"Recall of the third class is {:.2f}\".format(Recall_2))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Precision of the first class is {:.2f}\".format(Precision_0))\n",
    "print(\"Precision of the second class is {:.2f}\".format(Precision_1))\n",
    "print(\"Precision of the third class is {:.2f}\".format(Precision_2))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"F of the first class is {:.2f}\".format(F_0))\n",
    "print(\"F of the second class is {:.2f}\".format(F_1))\n",
    "print(\"F of the third class is {:.2f}\".format(F_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a6de7",
   "metadata": {
    "id": "c57a6de7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
